# scripts/generate_ai_prisma_rubric.py

import yaml
from pathlib import Path
from datetime import datetime
import sys


def generate_rubric_template(config):
    """
    Generate shareable AI-PRISMA rubric template from config
    Returns markdown template for transparency and reproducibility
    """

    rubric_config = config.get("ai_prisma_rubric", {})
    project_name = config.get("project_name", "Unnamed Project")
    research_question = config.get("research_question", "")

    template = f"""# AI-PRISMA Rubric Template

**Project**: {project_name}
**Research Question**: {research_question}
**Generated**: {datetime.now().strftime("%Y-%m-%d")}

## Overview

This rubric defines the AI-assisted screening criteria for systematic literature review.
Unlike traditional binary inclusion/exclusion, this rubric uses **multi-dimensional scoring**
with transparent reasoning and evidence grounding.

## Screening Model

- **LLM**: {rubric_config.get("llm", "claude-3-5-sonnet-20241022")}
- **Temperature**: {rubric_config.get("temperature", 0.1)}
- **Decision Mode**: Confidence-based with human review queue

## Decision Thresholds

"""

    dc = rubric_config.get("decision_confidence", {})
    template += f"""
| Decision | Confidence Range | Action |
|----------|------------------|--------|
| Auto-Include | ‚â•{dc.get("auto_include", 90)}% | Include without human review |
| Auto-Exclude | ‚â§{dc.get("auto_exclude", 10)}% | Exclude without human review |
| Human Review | {dc.get("auto_exclude", 10)+1}-{dc.get("auto_include", 90)-1}% | Flag for manual decision |

## Sub-Criteria Scoring (0-100 each)

"""

    sub_criteria = rubric_config.get("sub_criteria", {})
    for criterion, details in sub_criteria.items():
        template += f"""### {criterion.upper().replace("_", " ")}

**Description**: {details.get("description", "")}

**Scoring Rubric**:
```
{details.get("scoring_rubric", "Not specified")}
```

"""

    template += f"""## Human Validation (Optional)

- **Prompt User**: {rubric_config.get("human_validation", {}).get("prompt_user", True)}
- **Sample Size**: {rubric_config.get("human_validation", {}).get("sample_size", 100)} papers
- **Estimated Time**: {rubric_config.get("human_validation", {}).get("estimated_time_hours", 2.5)} hours

## Citation

If you use this rubric, please cite:

```bibtex
@misc{{ai_prisma_rubric_{datetime.now().year},
  title = {{AI-PRISMA Rubric for {project_name}}},
  author = {{[Your Name]}},
  year = {{{datetime.now().year}}},
  note = {{Systematic literature review screening rubric}},
  url = {{[Your Project URL]}}
}}
```

## Transparency Statement

This rubric was designed to maximize:
1. **Transparency**: Every decision includes evidence quotes
2. **Reproducibility**: Shared rubric allows verification
3. **Auditability**: AI reasoning is traceable to source text
4. **Academic Rigor**: Aligned with PRISMA 2020 standards

---

*Generated by ScholarRAG v1.0*
"""

    return template


# CLI
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python generate_ai_prisma_rubric.py <project-path>")
        print("Example: python generate_ai_prisma_rubric.py projects/my-project/")
        sys.exit(1)

    project_path = Path(sys.argv[1])
    config_path = project_path / "config.yaml"

    if not config_path.exists():
        print(f"‚ùå Config not found: {config_path}")
        sys.exit(1)

    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)

    # Generate rubric template
    print("\n" + "="*60)
    print("üìã GENERATING AI-PRISMA RUBRIC TEMPLATE")
    print("="*60 + "\n")

    rubric_md = generate_rubric_template(config)

    # Save to file
    output_path = project_path / "data/prisma/ai_rubric_template.md"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(rubric_md)

    print(f"‚úÖ Rubric template saved to: {output_path}")
    print(f"\nüìñ Review and share this rubric for transparency")
    print(f"\n" + "="*60 + "\n")
