# PRISMA íŒŒì´í”„ë¼ì¸ í†µí•©: Literature Review RAG ê°œì„  ì „ëµ

## ğŸ“‹ Executive Summary

**ëª©í‘œ**: AI failure_HR í”„ë¡œì íŠ¸ì˜ PRISMA ìŠ¤í¬ë¦¬ë‹ ë°©ë²•ë¡ ì„ Literature Review RAGì— í†µí•©í•˜ì—¬ **ë¬¸í—Œ í’ˆì§ˆ ìë™ í•„í„°ë§** ë° **ì²´ê³„ì  ë¬¸í—Œê³ ì°°(Systematic Review)** ê¸°ëŠ¥ ì œê³µ

**í˜„ì¬ ë¬¸ì œì **:
1. âœ— ì—…ë¡œë“œëœ PDFë¥¼ ë¬´ë¶„ë³„í•˜ê²Œ ì„ë² ë”© (í’ˆì§ˆ ê²€ì¦ ì—†ìŒ)
2. âœ— ì¤‘ë³µ ë¬¸í—Œ íƒì§€/ì œê±° ë¡œì§ ë¶€ì¬
3. âœ— ì—°êµ¬ ì£¼ì œì™€ ê´€ë ¨ì„± ì ìˆ˜í™” ì‹œìŠ¤í…œ ì—†ìŒ
4. âœ— HRM/HRD ê°™ì€ ë„ë©”ì¸ë³„ ë¶„ë¥˜ ê¸°ëŠ¥ ë¶€ì¬
5. âœ— ì„ì‹œ ì—…ë¡œë“œ í´ë” ì •ë¦¬ ëˆ„ë½ ([app.py:115](01_literature_review_rag/app.py#L115))

**ê¸°ëŒ€ íš¨ê³¼**:
- âœ… ì—°êµ¬ ì£¼ì œ ê´€ë ¨ì„± ê¸°ë°˜ ìë™ í•„í„°ë§ (PRISMA Stage 1-4)
- âœ… ë¬¸í—Œ í’ˆì§ˆ ì ìˆ˜ ì‹œê°í™” (relevance score dashboard)
- âœ… ì €í’ˆì§ˆ ë¬¸í—Œ ìë™ ì œì™¸ ë° ì¬ê²€í†  í ê´€ë¦¬
- âœ… ë„ë©”ì¸ë³„ ë¬¸í—Œ ë¶„ë¥˜ (HRM/HRD/Both ë“± í™•ì¥ ê°€ëŠ¥)
- âœ… PRISMA í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìë™ ìƒì„±

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1. ëª¨ë“ˆ êµ¬ì¡° (ì‹ ê·œ ì¶”ê°€)

```
01_literature_review_rag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ ingestion.py          # ê¸°ì¡´
â”‚   â”‚   â”œâ”€â”€ retrieval.py           # ê¸°ì¡´
â”‚   â”‚   â”œâ”€â”€ prisma_pipeline.py     # ğŸ†• PRISMA ìŠ¤í¬ë¦¬ë‹ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â””â”€â”€ quality_control.py     # ğŸ†• í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ document.py            # ê¸°ì¡´
â”‚   â”‚   â””â”€â”€ prisma_screening.py    # ğŸ†• ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ëª¨ë¸
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ deduplication.py       # ğŸ†• ì¤‘ë³µ ì œê±° ìœ í‹¸
â”‚       â””â”€â”€ scoring.py             # ğŸ†• ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/
â”‚   â”œâ”€â”€ screening/                 # ğŸ†• PRISMA ë‹¨ê³„ë³„ ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ 01_identification/
â”‚   â”‚   â”œâ”€â”€ 02_screening/
â”‚   â”‚   â”œâ”€â”€ 03_eligibility/
â”‚   â”‚   â””â”€â”€ 04_included/
â”‚   â””â”€â”€ vector_db/
â””â”€â”€ tests/
    â””â”€â”€ test_prisma.py             # ğŸ†• PRISMA í…ŒìŠ¤íŠ¸
```

### 2. ë°ì´í„° í”Œë¡œìš°

```
ğŸ“¤ PDF Upload
    â†“
[1] Identification Stage
    - íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì œëª©, ì €ì, ì—°ë„, DOI)
    - ì¤‘ë³µ ì²´í¬ (DOI/ì œëª© ê¸°ë°˜)
    - ì´ˆê¸° í†µê³„ ìƒì„±
    â†“
[2] Screening Stage (Title/Abstract)
    - ë„ë©”ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ (ì˜ˆ: HR/HRD)
    - AI/ML ê¸°ìˆ  í‚¤ì›Œë“œ í™•ì¸
    - ì—°êµ¬ ì£¼ì œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì˜ˆ: bias, fairness)
    - Exclusion í‚¤ì›Œë“œ ì²´í¬ (medical, pure tech)
    - ì´ˆê¸° ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (0-50ì )
    â†“
[3] Eligibility Stage (Full-text)
    - ì„¹ì…˜ ë¶„ì„ (Abstract, Methods, Results)
    - ì»¨í…ìŠ¤íŠ¸ ê²€ì¦ (ë„ë©”ì¸ ìš©ì–´ + HR ë§¥ë½)
    - ê³ ê¸‰ ì ìˆ˜ ê³„ì‚° (ë‹¤ì°¨ì› í‰ê°€)
    - ìµœì¢… ê´€ë ¨ì„± ì ìˆ˜ (0-100ì )
    â†“
[4] Inclusion Decision
    - ì ìˆ˜ ì„ê³„ê°’ ì ìš© (ê¸°ë³¸: 60ì )
    - ìŠ¹ì¸ â†’ Vector DB ì„ë² ë”©
    - ë³´ë¥˜ â†’ ìˆ˜ë™ ê²€í†  í
    - ì œì™¸ â†’ ì œì™¸ ì‚¬ìœ  ê¸°ë¡
    â†“
ğŸ—„ï¸ Vector Database (ê³ í’ˆì§ˆ ë¬¸í—Œë§Œ)
```

---

## ğŸ”¬ í•µì‹¬ êµ¬í˜„: PRISMA íŒŒì´í”„ë¼ì¸

### 3.1 `backend/core/prisma_pipeline.py`

**ì„¤ê³„ ì›ì¹™**:
- AI failure_HRì˜ `PRISMAScreener` í´ë˜ìŠ¤ë¥¼ **ë¬¸í—Œ ë¦¬ë·°ìš©ìœ¼ë¡œ ì¬ì„¤ê³„**
- **ë„ë©”ì¸ í‚¤ì›Œë“œë¥¼ ì„¤ì • íŒŒì¼ë¡œ ë¶„ë¦¬** (ì—°êµ¬ ì£¼ì œë³„ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥)
- **ì ì§„ì  í•„í„°ë§** (ê° ë‹¨ê³„ë³„ ì €ì¥ â†’ íˆ¬ëª…ì„±)

**í•µì‹¬ ê¸°ëŠ¥**:

```python
class LiteratureReviewPRISMA:
    """
    ë¬¸í—Œ ë¦¬ë·°ë¥¼ ìœ„í•œ PRISMA ìŠ¤í¬ë¦¬ë‹ ì‹œìŠ¤í…œ

    Features:
    - ì—°êµ¬ ì£¼ì œë³„ í‚¤ì›Œë“œ í”„ë¡œíŒŒì¼ ì§€ì›
    - ë‹¤ì°¨ì› ì ìˆ˜ ê³„ì‚° (domain, methodology, quality)
    - ì¤‘ë³µ ì œê±° (DOI, semantic similarity)
    - PRISMA í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìë™ ìƒì„±
    """

    def __init__(self, research_profile: ResearchProfile):
        """
        Args:
            research_profile: ì—°êµ¬ ì£¼ì œ ì •ì˜
                - domain_keywords: ë„ë©”ì¸ í‚¤ì›Œë“œ (ì˜ˆ: ['HRM', 'employee'])
                - method_keywords: ë°©ë²•ë¡  í‚¤ì›Œë“œ (ì˜ˆ: ['machine learning'])
                - topic_keywords: ì£¼ì œ í‚¤ì›Œë“œ (ì˜ˆ: ['bias', 'fairness'])
                - exclusion_keywords: ì œì™¸ í‚¤ì›Œë“œ
                - min_score: ìµœì†Œ í¬í•¨ ì ìˆ˜ (0-100)
        """

    def stage1_identification(self, documents: List[Document]) -> IdentificationResult:
        """
        Stage 1: ì‹ë³„
        - DOI/ì œëª© ê¸°ë°˜ ì¤‘ë³µ ì œê±°
        - ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ê²€ì¦
        - ì—°ë„/ì–¸ì–´ í•„í„°ë§
        """

    def stage2_screening(self, docs: List[Document]) -> ScreeningResult:
        """
        Stage 2: ì´ˆê¸° ìŠ¤í¬ë¦¬ë‹ (Title/Abstract)
        - ë„ë©”ì¸ í‚¤ì›Œë“œ ì ìˆ˜ (0-30ì )
        - ë°©ë²•ë¡  í‚¤ì›Œë“œ ì ìˆ˜ (0-20ì )
        - ì£¼ì œ í‚¤ì›Œë“œ ì ìˆ˜ (0-20ì )
        - ì œì™¸ í‚¤ì›Œë“œ ì²´í¬ (-30ì )
        - Title ë³´ë„ˆìŠ¤ (+10ì )
        """

    def stage3_eligibility(self, docs: List[Document]) -> EligibilityResult:
        """
        Stage 3: ì ê²©ì„± í‰ê°€ (Full-text)
        - ì„¹ì…˜ë³„ ë¶„ì„ (abstract, methods, results)
        - ì»¨í…ìŠ¤íŠ¸ ê²€ì¦ (ë„ë©”ì¸ ìš©ì–´ ë°€ë„)
        - ì¸ìš© í’ˆì§ˆ í‰ê°€
        - ì €ë„ ì„íŒ©íŠ¸ ê³ ë ¤ (optional)
        """

    def stage4_inclusion(self, docs: List[Document]) -> InclusionResult:
        """
        Stage 4: ìµœì¢… í¬í•¨ ê²°ì •
        - ì„ê³„ê°’ ì ìš©
        - ìˆ˜ë™ ê²€í†  í ìƒì„±
        - PRISMA í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        """

    def calculate_relevance_score(self, doc: Document) -> ScoringBreakdown:
        """
        ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (0-100)

        ë°˜í™˜:
            {
                'domain_score': 0-30,      # ë„ë©”ì¸ í‚¤ì›Œë“œ ë§¤ì¹­
                'method_score': 0-20,      # ë°©ë²•ë¡  í‚¤ì›Œë“œ
                'topic_score': 0-20,       # ì£¼ì œ í‚¤ì›Œë“œ
                'context_score': 0-20,     # ë§¥ë½ ê²€ì¦
                'quality_score': 0-10,     # í’ˆì§ˆ ì§€í‘œ
                'exclusion_penalty': 0/-30, # ì œì™¸ í‚¤ì›Œë“œ
                'total_score': 0-100
            }
        """
```

### 3.2 ì—°êµ¬ í”„ë¡œíŒŒì¼ ì˜ˆì‹œ (HRM/AI Bias ì—°êµ¬)

```python
# config/research_profiles/hrm_ai_bias.yaml

name: "HRM AI Bias Research"
description: "AI bias and fairness in HR practices"

domain_keywords:
  hrm:
    - "human resource management"
    - "employee selection"
    - "recruitment"
    - "hiring"
    - "performance appraisal"
    weight: 1.0

  hrd:
    - "employee training"
    - "learning and development"
    - "skill development"
    weight: 0.8

method_keywords:
  ai_ml:
    - "artificial intelligence"
    - "machine learning"
    - "algorithmic decision"
    - "automated hiring"
    weight: 1.0

topic_keywords:
  fairness:
    - "bias"
    - "discrimination"
    - "fairness"
    - "disparate impact"
    weight: 1.0

  ethics:
    - "ethics"
    - "transparency"
    - "accountability"
    weight: 0.9

exclusion_keywords:
  medical:
    - "alzheimer"
    - "clinical trial"
    - "patient care"
  technical:
    - "edge computing"
    - "IoT sensor"

scoring:
  min_score: 60          # ìµœì†Œ í¬í•¨ ì ìˆ˜
  review_threshold: 50   # ìˆ˜ë™ ê²€í†  í•„ìš” ì ìˆ˜
  auto_exclude: 30       # ìë™ ì œì™¸ ì ìˆ˜
```

---

## ğŸ”§ êµ¬í˜„ ë‹¨ê³„ë³„ í”Œëœ

### Phase 1: ê¸°ë°˜ ì‹œìŠ¤í…œ êµ¬ì¶• (1-2ì¼)

#### 1.1 PRISMA íŒŒì´í”„ë¼ì¸ í•µì‹¬ í´ë˜ìŠ¤
```bash
# ìƒˆ íŒŒì¼ ìƒì„±
touch backend/core/prisma_pipeline.py
touch backend/models/prisma_screening.py
touch backend/utils/deduplication.py
touch config/research_profiles/default.yaml
```

**êµ¬í˜„ ë‚´ìš©**:
- [ ] `LiteratureReviewPRISMA` í´ë˜ìŠ¤ (AI failure_HR ì½”ë“œ ë³€í˜•)
- [ ] `ResearchProfile` ë°ì´í„° ëª¨ë¸ (Pydantic)
- [ ] `ScoringEngine` (ë‹¤ì°¨ì› ì ìˆ˜ ê³„ì‚°)
- [ ] `DeduplicationEngine` (DOI + ì‹œë§¨í‹± ìœ ì‚¬ë„)

#### 1.2 í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/test_prisma.py

def test_end_to_end_screening():
    """ìƒ˜í”Œ PDF 5ê°œë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦"""

    # ì—°êµ¬ í”„ë¡œíŒŒì¼ ë¡œë“œ
    profile = ResearchProfile.from_yaml("config/research_profiles/hrm_ai_bias.yaml")

    # PRISMA íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    prisma = LiteratureReviewPRISMA(profile)

    # ë¬¸ì„œ ì²˜ë¦¬
    raw_docs = ingest_documents("tests/fixtures/sample_pdfs")

    # Stage 1-4 ìˆœì°¨ ì‹¤í–‰
    stage1 = prisma.stage1_identification(raw_docs)
    assert stage1.duplicates_removed > 0

    stage2 = prisma.stage2_screening(stage1.documents)
    assert stage2.excluded_count > 0

    stage3 = prisma.stage3_eligibility(stage2.documents)
    assert all(doc.score >= 50 for doc in stage3.documents)

    stage4 = prisma.stage4_inclusion(stage3.documents)
    assert len(stage4.included_docs) > 0

    # PRISMA í”Œë¡œìš° ìƒì„±
    assert stage4.flow_diagram_path.exists()
```

### Phase 2: Ingestion íŒŒì´í”„ë¼ì¸ ê°œì„  (2-3ì¼)

#### 2.1 `backend/core/ingestion.py` ìˆ˜ì •

**Before (í˜„ì¬)**:
```python
def upload_and_process(files):
    # 1. íŒŒì¼ ë³µì‚¬
    shutil.copy(file.name, temp_dir)

    # 2. ì¦‰ì‹œ ì„ë² ë”©
    documents = ingest_documents(temp_dir)
    retriever.add_documents(documents)  # âŒ í’ˆì§ˆ ê²€ì¦ ì—†ìŒ
```

**After (PRISMA í†µí•©)**:
```python
def upload_and_process_with_prisma(files, research_profile: str = "default"):
    # 1. ê¸°ë³¸ ì¸ì œìŠ¤ì…˜
    raw_docs = ingest_documents(temp_dir)

    # 2. PRISMA ìŠ¤í¬ë¦¬ë‹ ì ìš©
    profile = ResearchProfile.from_yaml(f"config/research_profiles/{research_profile}.yaml")
    prisma = LiteratureReviewPRISMA(profile)

    result = prisma.run_full_pipeline(raw_docs)

    # 3. í¬í•¨ëœ ë¬¸ì„œë§Œ Vector DBì— ì¶”ê°€
    retriever.add_documents(result.included_docs)

    # 4. ê²°ê³¼ ì €ì¥
    result.save_to_disk("data/screening/")

    # 5. ìƒíƒœ ë°˜í™˜
    return {
        'total_uploaded': len(files),
        'after_dedup': result.stage1.unique_count,
        'after_screening': result.stage2.passed_count,
        'after_eligibility': result.stage3.passed_count,
        'final_included': len(result.included_docs),
        'manual_review_needed': len(result.review_queue),
        'auto_excluded': result.excluded_count,
        'flow_diagram': result.flow_diagram_path
    }
```

#### 2.2 ì¤‘ë³µ ì œê±° ì „ëµ

```python
# backend/utils/deduplication.py

class DocumentDeduplicator:
    """
    ë‹¤ì¸µ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ
    """

    def remove_duplicates(self, docs: List[Document]) -> DeduplicationResult:
        """
        1. DOI ê¸°ë°˜ exact match
        2. ì œëª© ì •ê·œí™” í›„ exact match
        3. TF-IDF + Cosine Similarity (threshold: 0.95)
        4. MinHash LSH for scalability (1000+ papers)
        """

        # Level 1: DOI
        seen_dois = set()
        unique_docs = []

        for doc in docs:
            doi = doc.metadata.get('doi')
            if doi and doi in seen_dois:
                continue  # Skip duplicate
            if doi:
                seen_dois.add(doi)
            unique_docs.append(doc)

        # Level 2: Title normalization
        unique_docs = self._remove_title_duplicates(unique_docs)

        # Level 3: Semantic similarity (if > 100 papers)
        if len(unique_docs) > 100:
            unique_docs = self._remove_semantic_duplicates(unique_docs)

        return DeduplicationResult(
            original_count=len(docs),
            unique_count=len(unique_docs),
            duplicates_removed=len(docs) - len(unique_docs),
            documents=unique_docs
        )
```

### Phase 3: UI ê°œì„  (1-2ì¼)

#### 3.1 Gradio ì¸í„°í˜ì´ìŠ¤ ì—…ë°ì´íŠ¸

**ìƒˆ ê¸°ëŠ¥**:
1. **ì—°êµ¬ í”„ë¡œíŒŒì¼ ì„ íƒ**
   - ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì‚¬ì „ ì •ì˜ëœ í”„ë¡œíŒŒì¼ ì„ íƒ
   - ë˜ëŠ” ì»¤ìŠ¤í…€ í‚¤ì›Œë“œ ì…ë ¥

2. **PRISMA í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ í‘œì‹œ**
   - Mermaid.jsë¡œ ì‹¤ì‹œê°„ ë Œë”ë§
   ```
   Identification: 50 papers
        â†“
   Screening: 35 papers (15 excluded)
        â†“
   Eligibility: 28 papers (7 excluded)
        â†“
   Included: 25 papers (3 in manual review)
   ```

3. **ë¬¸í—Œ í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ**
   - ì ìˆ˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
   - ë„ë©”ì¸ ë¶„ë¥˜ íŒŒì´ ì°¨íŠ¸ (HRM/HRD/Both)
   - ì œì™¸ ì‚¬ìœ  ìš”ì•½

4. **ìˆ˜ë™ ê²€í†  í**
   - ë³´ë¥˜ ë¬¸í—Œ ëª©ë¡ (ì ìˆ˜ 50-59ì )
   - ìŠ¹ì¸/ê±°ë¶€ ë²„íŠ¼
   - ì‚¬ìœ  ì…ë ¥ í…ìŠ¤íŠ¸

**UI ë ˆì´ì•„ì›ƒ**:
```python
with gr.Tabs():
    with gr.Tab("ğŸ“¤ Upload & Screen"):
        gr.Dropdown(
            choices=["HRM AI Bias", "HRD Technology Adoption", "Custom"],
            label="Research Profile"
        )
        # ... ê¸°ì¡´ ì—…ë¡œë“œ UI

        # ğŸ†• PRISMA í”Œë¡œìš° í‘œì‹œ
        gr.Mermaid(label="PRISMA Flow Diagram")

        # ğŸ†• ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ìš”ì•½
        with gr.Row():
            gr.Number(label="Total Uploaded")
            gr.Number(label="After Dedup")
            gr.Number(label="Final Included")

    with gr.Tab("ğŸ“Š Quality Dashboard"):
        # ì ìˆ˜ ë¶„í¬
        gr.Plot(label="Relevance Score Distribution")

        # ë„ë©”ì¸ ë¶„ë¥˜
        gr.BarPlot(label="Domain Classification")

        # ì œì™¸ ì‚¬ìœ 
        gr.DataFrame(label="Exclusion Reasons")

    with gr.Tab("ğŸ” Manual Review Queue"):
        # ë³´ë¥˜ ë¬¸í—Œ ëª©ë¡
        review_queue = gr.DataFrame(
            headers=["Title", "Score", "Reason", "Actions"]
        )

        with gr.Row():
            gr.Button("âœ… Approve Selected")
            gr.Button("âŒ Reject Selected")
```

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ (Optional, 3-4ì¼)

#### 4.1 ì¬ìŠ¤í¬ë¦¬ë‹ ì‹œìŠ¤í…œ
```python
def rescore_collection(new_profile: ResearchProfile):
    """
    ê¸°ì¡´ ì»¬ë ‰ì…˜ì„ ìƒˆ ì—°êµ¬ í”„ë¡œíŒŒì¼ë¡œ ì¬í‰ê°€

    Use Case:
    - ì—°êµ¬ ë²”ìœ„ ë³€ê²½ (HRM â†’ HRM+HRD)
    - í‚¤ì›Œë“œ ì •ì œ
    - ì„ê³„ê°’ ì¡°ì •
    """

    # Vector DBì—ì„œ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
    all_docs = retriever.get_all_documents()

    # ìƒˆ í”„ë¡œíŒŒì¼ë¡œ ì¬ìŠ¤ì½”ì–´ë§
    prisma = LiteratureReviewPRISMA(new_profile)
    rescored = prisma.rescore_documents(all_docs)

    # ìƒˆë¡œ ì œì™¸ëœ ë¬¸ì„œ ì‹ë³„
    newly_excluded = [doc for doc in rescored if doc.score < new_profile.min_score]

    # Vector DBì—ì„œ ì œê±°
    retriever.remove_documents([doc.id for doc in newly_excluded])

    return RescoreResult(
        total_documents=len(all_docs),
        newly_excluded=len(newly_excluded),
        still_included=len(all_docs) - len(newly_excluded)
    )
```

#### 4.2 ë¬¸í—Œ ì¶”ì²œ ì‹œìŠ¤í…œ
```python
def recommend_missing_papers(current_collection: List[Document]) -> List[str]:
    """
    ì»¬ë ‰ì…˜ ë¶„ì„ í›„ ëˆ„ë½ ê°€ëŠ¥ì„± ìˆëŠ” ì£¼ì œ ì‹ë³„

    ë°©ë²•:
    1. í˜„ì¬ ë¬¸í—Œì˜ í‚¤ì›Œë“œ/ì£¼ì œ ì¶”ì¶œ
    2. í‚¤ì›Œë“œ ê³µê°„ì—ì„œ sparse ì˜ì—­ íƒì§€
    3. í•´ë‹¹ ì˜ì—­ ì»¤ë²„í•  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    """

    # ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§ (BERTopic)
    topics = extract_topics(current_collection)

    # Coverage gap ë¶„ì„
    gaps = identify_coverage_gaps(topics)

    # ê²€ìƒ‰ ì¿¼ë¦¬ ì œì•ˆ
    queries = [
        f"{gap.topic} AND {gap.missing_aspect}"
        for gap in gaps
    ]

    return queries
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 5.1 ë°°ì¹˜ ì²˜ë¦¬ ì „ëµ

**ëŒ€ëŸ‰ ì—…ë¡œë“œ ì‹œë‚˜ë¦¬ì˜¤ (100+ papers)**:
```python
async def batch_process_with_prisma(files: List[Path], batch_size: int = 20):
    """
    ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
    """

    total_batches = len(files) // batch_size + 1

    for i in range(0, len(files), batch_size):
        batch = files[i:i+batch_size]

        # ë³‘ë ¬ PDF íŒŒì‹±
        raw_docs = await asyncio.gather(*[
            parse_pdf_async(file) for file in batch
        ])

        # PRISMA ìŠ¤í¬ë¦¬ë‹ (CPU-bound)
        with ProcessPoolExecutor() as executor:
            screened = await loop.run_in_executor(
                executor,
                prisma.run_full_pipeline,
                raw_docs
            )

        # ì ì§„ì  Vector DB ì—…ë°ì´íŠ¸
        retriever.add_documents(screened.included_docs)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        yield {
            'progress': (i + batch_size) / len(files),
            'current_batch': i // batch_size + 1,
            'total_batches': total_batches
        }
```

### 5.2 ìºì‹± ì „ëµ
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def calculate_relevance_score(doc_hash: str, profile_hash: str) -> float:
    """
    ë™ì¼ ë¬¸ì„œ + ë™ì¼ í”„ë¡œíŒŒì¼ = ìºì‹œëœ ì ìˆ˜ ë°˜í™˜
    """
    pass
```

---

## ğŸ§ª ê²€ì¦ ì „ëµ

### 6.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/test_prisma.py

def test_doi_deduplication():
    """DOI ì¤‘ë³µ ì œê±° ê²€ì¦"""
    pass

def test_title_normalization():
    """ì œëª© ì •ê·œí™” ë° ì¤‘ë³µ íƒì§€"""
    pass

def test_scoring_consistency():
    """ë™ì¼ ë¬¸ì„œ â†’ ë™ì¼ ì ìˆ˜ ë³´ì¥"""
    pass

def test_exclusion_keywords():
    """ì œì™¸ í‚¤ì›Œë“œ ì •í™•ë„"""
    pass
```

### 6.2 í†µí•© í…ŒìŠ¤íŠ¸
```python
def test_full_pipeline_with_real_papers():
    """
    ì‹¤ì œ ë…¼ë¬¸ 50í¸ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦

    Fixtures:
    - 25í¸: HRM AI bias papers (high relevance)
    - 15í¸: Medical AI papers (should exclude)
    - 10í¸: Education AI papers (medium relevance)
    """

    # ê¸°ëŒ€ ê²°ê³¼
    assert included_count >= 20  # HRM papers
    assert excluded_count >= 15  # Medical papers
    assert review_queue_count >= 5  # Education papers (border cases)
```

---

## ğŸ“ˆ í–¥í›„ í™•ì¥

### 7.1 ë©”íƒ€ë¶„ì„ ì§€ì›
- íš¨ê³¼í¬ê¸°(effect size) ì¶”ì¶œ ìë™í™”
- Cohen's d, Correlation coefficient íƒì§€
- ë©”íƒ€ë¶„ì„ìš© ë°ì´í„°ì…‹ ìƒì„±

### 7.2 í˜‘ì—… ìŠ¤í¬ë¦¬ë‹
- ë‹¤ì¤‘ í‰ê°€ì ì§€ì› (Cohen's Kappa ê³„ì‚°)
- ë¶ˆì¼ì¹˜ í•´ì†Œ ì›Œí¬í”Œë¡œìš°
- ìŠ¤í¬ë¦¬ë‹ ì´ë ¥ ì¶”ì 

### 7.3 í•™ìˆ  API í†µí•©
- Semantic Scholar APIë¡œ ëˆ„ë½ ë…¼ë¬¸ ìë™ ë°œê²¬
- CrossRefë¡œ ì¸ìš© ê´€ê³„ ë§¤í•‘
- OpenAlexë¡œ ì €ë„ ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘

---

## âœ… êµ¬í˜„ ìš°ì„ ìˆœìœ„

**Must Have (MVP)**:
1. âœ… PRISMA 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
2. âœ… ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
3. âœ… ì¤‘ë³µ ì œê±° (DOI + Title)
4. âœ… ì—°êµ¬ í”„ë¡œíŒŒì¼ ì‹œìŠ¤í…œ
5. âœ… Gradio UI ì—…ë°ì´íŠ¸

**Should Have (v1.1)**:
6. âœ… PRISMA í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨
7. âœ… ìˆ˜ë™ ê²€í†  í
8. âœ… í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
9. âœ… ì¬ìŠ¤í¬ë¦¬ë‹ ê¸°ëŠ¥

**Nice to Have (v2.0)**:
10. â­ ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
11. â­ ë¬¸í—Œ ì¶”ì²œ ì‹œìŠ¤í…œ
12. â­ ë©”íƒ€ë¶„ì„ ì§€ì›
13. â­ í˜‘ì—… ìŠ¤í¬ë¦¬ë‹

---

## ğŸš€ ì‹¤í–‰ ê³„íš

### Week 1: í•µì‹¬ íŒŒì´í”„ë¼ì¸
- Day 1-2: `prisma_pipeline.py` êµ¬í˜„
- Day 3: ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ
- Day 4: í…ŒìŠ¤íŠ¸ ì‘ì„±
- Day 5: `ingestion.py` í†µí•©

### Week 2: UI & í’ˆì§ˆ ê´€ë¦¬
- Day 1-2: Gradio UI ê°œì„ 
- Day 3: í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
- Day 4: ìˆ˜ë™ ê²€í†  í
- Day 5: ë¬¸ì„œí™” & ë°°í¬

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [PRISMA 2020 Statement](http://www.prisma-statement.org/)
- [AI failure_HR PRISMA Implementation](../AI%20failure_HR/code/collection/prisma_screening_protocol.py)
- [LangChain Document Transformers](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [ChromaDB Metadata Filtering](https://docs.trychroma.com/usage-guide#filtering-by-metadata)

---

**ì‘ì„±ì¼**: 2025-01-10
**ì‘ì„±ì**: Claude Code
**ìƒíƒœ**: ì „ëµ ìˆ˜ë¦½ ì™„ë£Œ â†’ êµ¬í˜„ ëŒ€ê¸°
