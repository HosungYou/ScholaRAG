# ResearcherRAG: Build Your Own Research RAG System with Claude Code

**Learn to build custom RAG systems for academic research through conversational AI assistance in VS Code**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Powered by Claude Code](https://img.shields.io/badge/Claude-Code-orange)](https://claude.com/claude-code)

---

## ğŸ¯ What is ResearcherRAG?

ResearcherRAG helps researchers build **custom RAG (Retrieval-Augmented Generation) systems** for their literature review through **conversational interaction with Claude Code** in VS Code.

### What You'll Build

In 3 hours, you'll create:
- âœ… **PRISMA Systematic Review Pipeline**: Screen 500+ papers down to 50-150 highly relevant ones
- âœ… **Custom Vector Database**: Semantic search across your included papers
- âœ… **Research-Focused RAG**: Query system that cites specific papers with methods and findings

### Why This Approach?

**Traditional Method** (6-8 weeks):
1. Manual database searches (PubMed, ERIC, Web of Science)
2. Export to Excel, read 500+ abstracts one by one
3. Full-text review of 200+ papers
4. Extract findings manually
5. Constantly re-read papers for citations

**With ResearcherRAG** (2-3 weeks):
1. **3-hour workshop**: Build RAG system with Claude Code guidance
2. **2 hours**: PRISMA screens 20,555 papers â†’ 592 papers automatically
3. **Ongoing**: Query RAG for instant answers with citations
4. **Result**: 67-75% time savings, never forget a relevant paper

---

## ğŸš€ Quick Start

### Prerequisites

- **VS Code** with **Claude Code extension** installed
- **Python 3.9+**
- **3 hours** for initial setup

### 5-Minute Start

```bash
# 1. Clone repository
git clone https://github.com/HosungYou/ResearcherRAG.git
cd ResearcherRAG

# 2. Install dependencies
pip install -r requirements.txt

# 3. Open in VS Code
code .

# 4. Start Claude Code chat (Cmd+Shift+P â†’ "Claude: Open Chat")

# 5. Copy-paste prompt from prompts/01_research_domain_setup.md
```

**That's it!** Claude Code will guide you through:
- Stage 1: Define research scope (15 min)
- Stage 2: Design search queries (10 min)
- Stage 3: Configure PRISMA screening (20 min)
- Stage 4: Design RAG system (15 min)
- Stage 5: Execute pipeline (3-4 hours, mostly waiting)

---

## ğŸ“š What's Included

### ğŸ“ Educational Materials

#### **CLAUDE.md** (18,000 words)
Complete guide for Claude Code on how to assist researchers. Covers:
- 5-stage conversational workflow
- Domain-specific examples (Education, Medicine, Psychology)
- Troubleshooting common issues
- Best practices for research RAG

#### **5-Stage Prompt Templates** (`prompts/`)
Copy-paste prompts for each stage:
1. **Research Domain Setup**: Define scope, questions, constraints
2. **Query Strategy**: Design boolean queries, choose data sources
3. **PRISMA Configuration**: Build multi-dimensional screening
4. **RAG Design**: PDF acquisition, text extraction, vector DB, prompts
5. **Execution Plan**: Run pipeline, troubleshoot, validate

#### **Workshop Guide** (3 hours, `workshop/hands_on_guide.md`)
Complete curriculum for teaching ResearcherRAG:
- Part 1: Introduction & Demo (30 min)
- Part 2: Hands-on Exercises (90 min)
- Part 3: Advanced Topics (30 min)
- Part 4: Wrap-up & Resources (30 min)

### ğŸ› ï¸ Templates

#### **Research Profiles** (`templates/research_profiles/`)
Pre-configured YAML templates for:
- **Education**: K-12, higher ed, learning sciences, edtech
- **Medicine**: Clinical trials, EHR, public health, telemedicine
- **Social Science**: Psychology, sociology, economics, political science

Each includes:
- Domain/method/topic keyword lists with weights
- Exclusion criteria
- PRISMA threshold recommendations
- Customization examples

#### **Code Templates** (`backend/core/`)
Production-ready Python implementation:
- **prisma_pipeline.py**: 4-stage PRISMA screening
- **research_profile.py**: YAML-based profile management
- **rag_graph.py**: LangGraph-based retrieval
- **retrieval.py**: Vector DB query logic

---

## ğŸ“– How It Works

### The 5-Stage Workflow

```
Stage 1: Research Domain Setup (15 min)
â””â”€â†’ You describe research topic
    â””â”€â†’ Claude asks clarifying questions
        â””â”€â†’ Output: Clear research scope

Stage 2: Query Strategy (10 min)
â””â”€â†’ Claude designs search queries (broad/focused/narrow)
    â””â”€â†’ You select and refine
        â””â”€â†’ Output: Optimized boolean queries

Stage 3: PRISMA Configuration (20 min)
â””â”€â†’ Collect papers via API (Semantic Scholar, OpenAlex)
    â””â”€â†’ Claude analyzes metadata
        â””â”€â†’ Auto-generates research profile (YAML)
            â””â”€â†’ You review and adjust
                â””â”€â†’ Run PRISMA screening
                    â””â”€â†’ Output: 50-150 included papers

Stage 4: RAG Design (15 min)
â””â”€â†’ Configure PDF download strategy
    â””â”€â†’ Set text extraction tools
        â””â”€â†’ Design chunking and embeddings
            â””â”€â†’ Choose vector database
                â””â”€â†’ Engineer RAG prompts
                    â””â”€â†’ Output: Complete RAG configuration

Stage 5: Execution (3-4 hours, mostly automated)
â””â”€â†’ Download PDFs (2-3 hours, 50-60% success)
    â””â”€â†’ Extract text (30 min)
        â””â”€â†’ Build vector database (15 min)
            â””â”€â†’ Test with sample queries (15 min)
                â””â”€â†’ Output: Functional RAG system!
```

### Example: Education Research

**Research Question**: "Do AI chatbots improve speaking proficiency in language learning?"

**Stage 1**: Scope defined (higher education, experimental studies, 2015-2024)

**Stage 2**: Query designed
```
(chatbot OR conversational agent) AND
(language learning OR L2) AND
(university OR college) AND
(experimental OR RCT)
```

**Stage 3**: PRISMA screening
- Collected: 568 papers (Semantic Scholar)
- Screened: 342 passed title/abstract (60%)
- Eligible: 139 passed detailed assessment (24%)
- Included: 139 papers for RAG

**Stage 4**: RAG configured
- Embedding: all-MiniLM-L6-v2 (local, free)
- Vector DB: ChromaDB (687 chunks, 23 MB)
- System prompt: Academic citations required

**Stage 5**: Execution results
- PDFs downloaded: 75/139 (54%)
- Text extracted: 71/75 (95%)
- Vector DB built: 687 chunks indexed
- Ready to query!

**Query Example**:
```
Q: "What are the main effects of chatbots on speaking proficiency?"

A: Research shows moderate to large positive effects:

**Fluency**: +15-30% speaking rate [Kim et al., 2023, RCT, N=120,
d=0.68, p<.001]. Lower-proficiency learners benefited most [Lee &
Park, 2022, Quasi-exp, N=89, Î·Â²=0.42].

**Accuracy**: Significant grammar improvements [Chen, 2024, RCT,
N=156, d=0.51, p<.01], especially syntax errors.

**Confidence**: Increased willingness to communicate after 8 weeks
[Martinez et al., 2023, Pre-post, N=94, d=0.73].

**Limitations**: Most studies <3 months, self-report bias, limited
L1 diversity.

ğŸ“š 8 papers cited
```

---

## ğŸ“ Use Cases

### 1. PhD Dissertation Literature Review
- **Before**: 8 weeks reading 300 papers
- **After**: 3 weeks (RAG setup + querying)
- **Benefit**: Never forget relevant citations

### 2. Meta-Analysis Preparation
- **Before**: 4 weeks extracting effect sizes manually
- **After**: 1 week (RAG-assisted extraction)
- **Benefit**: Consistent extraction criteria

### 3. Grant Proposal Background
- **Before**: Re-read 50 papers for each grant
- **After**: Query RAG for specific evidence
- **Benefit**: Always current, comprehensive citations

### 4. Systematic Review (PRISMA 2020)
- **Before**: 2 weeks manual title/abstract screening
- **After**: 2 hours automated PRISMA
- **Benefit**: Reproducible, documented criteria

---

## ğŸ† Success Stories

### AI failure_HR Project (Real-world Example)
- **Papers Collected**: 20,555 from OpenAlex
- **PRISMA Screening**: 2 hours (vs. 2 weeks manual)
- **Papers Included**: 592 (2.9% selection rate)
- **PDF Success**: 316/592 (53.4%)
- **Final RAG**: 316 full-text papers, instant queries
- **Result**: Research paper published using this methodology

### Workshop Testimonials
> "I spent 3 months on my lit review last year. With ResearcherRAG,
> I set up a better system in 3 hours." - PhD Student, Education

> "PRISMA screening that took my RA 2 weeks now takes 2 hours.
> Game changer." - Associate Professor, Psychology

> "Finally, a systematic review tool that doesn't require coding
> expertise." - Research Librarian

---

## ğŸ“Š Key Features

### PRISMA 2020 Compliance
- 4-stage screening (Identification â†’ Screening â†’ Eligibility â†’ Inclusion)
- Multi-dimensional relevance scoring (6 dimensions)
- Automatic flow diagram generation
- Manual review queue for borderline papers
- Reproducible with YAML configuration

### Multi-Source Data Collection
- Semantic Scholar (200M papers, free API)
- OpenAlex (250M works, comprehensive metadata)
- arXiv (STEM preprints, full-text PDFs)
- PubMed (Medicine, PMC full-text subset)
- ERIC (Education research)

### Intelligent PDF Acquisition
- **Tier 1**: Open Access (Unpaywall, OpenAlex) - 95% success
- **Tier 2**: Institutional proxy (VPN) - 80% success
- **Tier 3**: Author requests (email templates) - 30% success
- **Tier 4**: Abstract-only fallback (better than nothing)
- **Expected**: 50-60% overall success rate

### Research-Grade RAG
- **Citation Format**: [Author, Year, Design, N=X, Finding/Effect size]
- **Quality Control**: Minimum similarity threshold (0.65)
- **Re-ranking**: Cross-encoder for better relevance
- **Transparency**: Show retrieved sources with scores
- **Limitations**: Acknowledges gaps in literature

---

## ğŸ› ï¸ Technology Stack

- **LLM**: Claude 3.5 Sonnet (via Claude Code)
- **RAG Framework**: LangGraph (query decomposition, parallel retrieval)
- **Vector DB**: ChromaDB (local, persistent)
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2 (free, local)
- **PDF Processing**: PyMuPDF, pdfplumber, Tesseract OCR
- **PRISMA**: Custom Python implementation (multi-dimensional scoring)

---

## ğŸ“… Roadmap

### v1.1.0 (Current - 2025-10-25)
- âœ… Complete 5-stage prompt templates
- âœ… CLAUDE.md (18,000-word guide)
- âœ… Workshop curriculum (3 hours)
- âœ… Research profile templates (3 domains)
- â³ README and documentation updates
- â³ Example project (ai_education_chatbot)

### v1.2.0 (2025-11-15)
- Bookdown-style online documentation site
- 14-chapter comprehensive guide
- Additional example projects (Medicine, Psychology)
- Video tutorial series (10 x 15min)
- Community forum launch

### v1.3.0 (2026-01-15)
- Citation graph analysis
- Temporal trend analysis
- Multi-lingual RAG (Korean, Chinese, Spanish)
- Automated meta-analysis (effect size extraction)

### v2.0.0 (2026-Q2)
- Collaborative RAG (multi-user projects)
- Cloud-hosted option (optional)
- Integration with reference managers (Zotero, Mendeley)
- Writing assistance (related work section generation)

See [project_management/ROADMAP.md](project_management/ROADMAP.md) for details.

---

## ğŸ¤ Contributing

We welcome contributions!

### Ways to Contribute
- **Share Templates**: Add research profiles for your domain
- **Report Bugs**: Open GitHub issues
- **Improve Docs**: Fix typos, clarify instructions
- **Success Stories**: Share your research using ResearcherRAG

See [project_management/TODO.md](project_management/TODO.md) for current tasks.

---

## ğŸ“š Resources

### Documentation
- **[CLAUDE.md](CLAUDE.md)**: Complete guide for Claude Code
- **[prompts/](prompts/)**: 5-stage prompt templates
- **[workshop/hands_on_guide.md](workshop/hands_on_guide.md)**: 3-hour workshop
- **[release-notes/v1.1.0.md](release-notes/v1.1.0.md)**: What's new

### Project Management
- **[TODO.md](project_management/TODO.md)**: Current tasks
- **[ROADMAP.md](project_management/ROADMAP.md)**: Long-term vision
- **[CHANGELOG.md](project_management/CHANGELOG.md)**: Version history

### Community
- **GitHub Issues**: Bug reports and feature requests
- **GitHub Discussions**: Questions and tips
- **Workshop Forum**: [Discord/Slack] (coming in v1.2.0)

---

## ğŸ“– Citation

If you use ResearcherRAG in your research, please cite:

```bibtex
@software{researcherrag2025,
  author = {[Your Name]},
  title = {ResearcherRAG: Build Your Own Research RAG System with Claude Code},
  year = {2025},
  url = {https://github.com/HosungYou/ResearcherRAG},
  version = {1.1.0}
}
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Claude Code** (Anthropic) for conversational AI assistance
- **AI failure_HR Project** for real-world PRISMA validation (20,555 papers)
- **PRISMA 2020 Guidelines** for systematic review methodology
- **LangChain/LangGraph** for RAG framework
- **Research Community** for feedback and use cases

---

## ğŸ“ Contact

- **GitHub Issues**: https://github.com/HosungYou/ResearcherRAG/issues
- **Email**: [Your email] (for workshop inquiries)

---

**Built with â¤ï¸ for researchers, by researchers**

_Powered by [Claude Code](https://claude.com/claude-code) ğŸ¤–_
